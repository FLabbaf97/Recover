{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import importlib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from recover.utils.utils import get_tensor_dataset\n",
    "import reservoir as rdl\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Methods to get different types of loaders\n",
    "#####################################\n",
    "\n",
    "\n",
    "def get_regular_valid_loader(trainer):\n",
    "    return trainer.valid_loader\n",
    "\n",
    "def get_test_loader(trainer):\n",
    "    test_dataset = get_tensor_dataset(trainer.data, trainer.test_idxs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "    \n",
    "    return test_loader\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Iterator over trainers for a given config\n",
    "#####################################\n",
    "\n",
    "\n",
    "def trainer_iterator(config_file, path_to_conf):\n",
    "    configuration = importlib.import_module(\"recover.config.\" + config_file).configuration\n",
    "\n",
    "    # Loop over all runs for this configuration\n",
    "    for run_dir in tqdm(os.listdir(os.path.join(path_to_conf, config_file))):\n",
    "        print(run_dir)\n",
    "        if run_dir.startswith('BasicTrainer'):\n",
    "\n",
    "            this_run_results = {}\n",
    "\n",
    "            # Load params for that run\n",
    "            with open(os.path.join(path_to_conf, config_file, run_dir, 'params.json')) as f:\n",
    "                params = json.load(f)\n",
    "\n",
    "            # Load configuration (can contain grid_search args)\n",
    "            this_run_config = deepcopy(configuration)\n",
    "\n",
    "            # Replace grid_search args by the actual parameter for that run\n",
    "            for key in this_run_config['trainer_config']:\n",
    "                if type(this_run_config['trainer_config'][key]) is dict \\\n",
    "                and 'grid_search' in this_run_config['trainer_config'][key].keys():\n",
    "                    \n",
    "                    # If grid search over python classes, we need to load them\n",
    "                    if type(params[key]) is str and params[key].startswith('<class'):\n",
    "                        class_to_load = params[key]\n",
    "                        class_to_load = class_to_load.split(\"'\")[1]\n",
    "                        class_to_load = class_to_load.rpartition('.')\n",
    "                        path_to_class = class_to_load[0]\n",
    "                        class_to_load_name = class_to_load[-1]\n",
    "                        params[key] = getattr(importlib.import_module(path_to_class), \n",
    "                                              class_to_load_name)\n",
    "                    this_run_config['trainer_config'][key] = params[key]\n",
    "                    this_run_results[key] = params[key]\n",
    "\n",
    "            # Load trainer\n",
    "            trainer = this_run_config[\"trainer\"](this_run_config[\"trainer_config\"])\n",
    "\n",
    "            # Find the checkpoint corresponding to the best epoch (always two checkpoints, \n",
    "            # corresponding to best and last epochs)\n",
    "            cpt = 0\n",
    "            checkpoint = None\n",
    "            for dir_check in os.listdir(os.path.join(path_to_conf, config_file, run_dir)):\n",
    "                if dir_check.startswith('checkpoint'):\n",
    "                    cpt += 1\n",
    "                    if checkpoint is None:\n",
    "                        checkpoint = dir_check\n",
    "                    else:\n",
    "                        if int(dir_check.split('_')[-1]) < int(checkpoint.split('_')[-1]):\n",
    "                            checkpoint = dir_check\n",
    "                            \n",
    "            if cpt == 2:\n",
    "                # Only yield trainer if 2 checkpoints have been saved (corresponding to best and last epochs)\n",
    "\n",
    "                # Load model\n",
    "                trainer.model.load_state_dict(torch.load(path_to_conf + config_file + \"/\" + \n",
    "                                                 run_dir + \"/\" + checkpoint + \"/model.pth\",\n",
    "                                                 map_location=torch.device('cpu')))\n",
    "                print(\"Loaded model from\", run_dir, checkpoint)\n",
    "                \n",
    "                yield trainer\n",
    "\n",
    "#####################################\n",
    "# Main evaluation method\n",
    "#####################################\n",
    "\n",
    "\n",
    "def evaluate_config(config_file, path_to_conf, get_eval_loader=get_regular_valid_loader):\n",
    "    all_results = pd.DataFrame()\n",
    "\n",
    "    for trainer in trainer_iterator(config_file, path_to_conf):\n",
    "        \n",
    "        this_run_results = {}\n",
    "\n",
    "        # Evaluate\n",
    "        eval_metrics, _ = trainer.eval_epoch(trainer.data, get_eval_loader(trainer), \n",
    "                                             trainer.model)\n",
    "\n",
    "        # Create dataframe for this run\n",
    "        print(\"this run results\", this_run_results)\n",
    "        print(\"eval metrics\", eval_metrics)\n",
    "\n",
    "        this_run_results = {**this_run_results, **eval_metrics}\n",
    "        for key in this_run_results.keys():\n",
    "            this_run_results[key] = [this_run_results[key]]\n",
    "\n",
    "        this_run_df = pd.DataFrame.from_dict(this_run_results)\n",
    "\n",
    "        all_results = all_results.append(this_run_df)\n",
    "\n",
    "    all_results.reset_index()\n",
    "        \n",
    "    return all_results\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair level split (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.242 \\pm 0.006\n",
      "spearman 0.466 \\pm 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_evaluation\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_test_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.343 \\pm 0.053\n",
      "spearman 0.474 \\pm 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_evaluation\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_regular_valid_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Level Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recover.datasets.drugcomb_matrix_data import DrugCombMatrixDrugLevelSplitTest\n",
    "\n",
    "def get_drug_split_test_loader(trainer):\n",
    "    \n",
    "    dl_split_data = DrugCombMatrixDrugLevelSplitTest(cell_line='MCF7',\n",
    "                                     fp_bits=1024,\n",
    "                                     fp_radius=2)\n",
    "    dl_split_data.data.ddi_edge_response = dl_split_data.data.ddi_edge_bliss_max\n",
    "    \n",
    "    test_idxs = range(len(dl_split_data.data.ddi_edge_response))\n",
    "    \n",
    "    test_dataset = get_tensor_dataset(dl_split_data.data, test_idxs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.038 \\pm 0.002\n",
      "spearman 0.157 \\pm 0.012\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_drug_level_split\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_drug_split_test_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.401 \\pm 0.147\n",
      "spearman 0.459 \\pm 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_drug_level_split\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_regular_valid_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Cell Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mcf7_test_loader(trainer):\n",
    "\n",
    "    mcf7_idxs = np.where(np.array(trainer.data.ddi_edge_classes) == trainer.data.cell_line_to_idx_dict['MCF7'])[0]\n",
    "    \n",
    "    mcf7_test_idxs = list(set(np.array(trainer.test_idxs)).intersection(mcf7_idxs))\n",
    "    mcf7_test_idxs = torch.Tensor(mcf7_test_idxs).long()\n",
    "\n",
    "    test_dataset = get_tensor_dataset(trainer.data, mcf7_test_idxs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.282 \\pm 0.017\n",
      "spearman 0.448 \\pm 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_evaluation_multi_cell_line\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_mcf7_test_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:34<00:00, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.387 \\pm 0.032\n",
      "spearman 0.518 \\pm 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_evaluation_multi_cell_line\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_regular_valid_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Line Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:25<00:00, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.382 \\pm 0.017\n",
      "spearman 0.378 \\pm 0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"cell_line_transfer\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_test_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [12:10<00:00, 121.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.278 \\pm 0.027\n",
      "spearman 0.299 \\pm 0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"cell_line_transfer\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_regular_valid_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recover.datasets.drugcomb_matrix_data import DrugCombMatrixTestAlmanac\n",
    "\n",
    "def get_trimmed_Almanac_test_loader(trainer):\n",
    "    \n",
    "    dl_split_data = DrugCombMatrixTestAlmanac(cell_line=None,\n",
    "                                     fp_bits=1024,\n",
    "                                     fp_radius=2)\n",
    "    dl_split_data.data.ddi_edge_response = dl_split_data.data.ddi_edge_bliss_max\n",
    "    \n",
    "    test_idxs = range(len(dl_split_data.data.ddi_edge_response))\n",
    "    \n",
    "    test_dataset = get_tensor_dataset(dl_split_data.data, test_idxs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.014 \\pm 0.016\n",
      "spearman 0.147 \\pm 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"pretrain_ONEIL\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_trimmed_Almanac_test_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:22<00:00,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.304 \\pm 0.021\n",
      "spearman 0.589 \\pm 0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"pretrain_ONEIL\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/RECOVERcoalition/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_regular_valid_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "print(\"R2\", round(all_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['comb_r_squared'].std(),3))\n",
    "print('spearman', round(all_results['spearman'].mean(), 3), \"\\pm\", \n",
    "      round(all_results['spearman'].std(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('recover')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "65b6bd34e70580b739e2ef4ddfafaabd45cf47fba64cadc9dbf2a0c92f146506"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
